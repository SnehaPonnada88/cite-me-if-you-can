# 🧠 Cite Me If You Can

A mini data science challenge that combines **semantic search** + **LLM-powered Q&A** on academic research chunks.  
Built using FastAPI, Qdrant vector database, Sentence Transformers, and OpenAI GPT.

---

## 🚀 What It Does

> Give me context, and I’ll cite it back.

This system enables two main features:

1. **Semantic Similarity Search**  
   Search through academic chunks using vector embeddings and retrieve the most relevant ones.

2. **GPT-powered Contextual Answering**  
   Ask research questions, and receive answers generated by OpenAI GPT with real citations from source documents.

---


## 🧪 API Endpoints

> Testable via Swagger UI at [`/docs`](http://127.0.0.1:8000/docs)


## Tech Stack

🧠 OpenAI GPT-3.5 Turbo

🔍 Qdrant vector search

🧾 Sentence Transformers (all-MiniLM-L6-v2)

⚡ FastAPI

🐳 Docker (for Qdrant container)

## 🛠️ Setup & Run
bash

# 1. Create virtual env
conda create -n cite-ai python=3.10
conda activate cite-ai

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run Qdrant in Docker
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

# 4. Run the FastAPI app
uvicorn main:app --reload

# 5. Open the Swagger UI
http://127.0.0.1:8000/docs

## '📦 Versioning'

v0.1 – Initial folders setup
v0.2 – Ingestion pipeline setupwith embedding and Qdrant Integration
v0.3 – Similarity Search Endpoint
v0.4 – Dockerized Qdrant integration
v0.5 - GPT Answer API Endpoint
v0.6 - Upload Endpoint
v0.7 – Usage count for endpoint tracking



